{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdca525",
   "metadata": {},
   "source": [
    "# TP YAMS - EL KETTANEH Joseph - M2 SD\n",
    "##### Yams is a well-known dice game in which the goal is to achieve a high score by rolling certain dice combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954280d",
   "metadata": {},
   "source": [
    "# Computing the optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bbf892",
   "metadata": {},
   "source": [
    "## In The following code we have the functions used to compute the optimal policy\n",
    "\n",
    "- get_states(nb_dices,nb_faces):\n",
    "    - Returns the set of states S and the probability of each state for a defined number of dices anf faces\n",
    "- get_actions_from_state(my_States,nb_faces)\n",
    "    - Returns the set of actions that can be taken for a defined state\n",
    "- get_states_from_action(my_actions,nb_dices)\n",
    "    - Returns the set of states of a taken Action and the probability of each state\n",
    "- get_state_index(my_state,my_states,nb_faces)\n",
    "    - Returns the index of state of the set of states\n",
    "- set_last_rewards(s,nb_faces) \n",
    "    - Returns the game score as reward\n",
    "- optimal_policy(nb_dices, nb_faces)\n",
    "    - Returns the value function v ∈ R|S|×3 and the optimal policy as the best action a∗(s) for each state, π ∈ N|S|×6×3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e76d10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools\n",
    "from itertools import product\n",
    "\n",
    "#function to roll the dice\n",
    "def roll():\n",
    "    dices_init = np.zeros(NB_DICES,dtype='int')\n",
    "    faces_init = np.zeros(NB_FACES,dtype='int')\n",
    "    for i in range(NB_DICES):\n",
    "        face = random.randint(1,NB_FACES)\n",
    "        faces_init[face- 1] += 1\n",
    "    return faces_init\n",
    "\n",
    "def get_states(nb_dices,nb_faces):\n",
    "    S = []\n",
    "    for it in (itertools.product(range(nb_faces) , repeat = nb_dices)):\n",
    "        s = np.zeros((nb_faces), dtype='int')\n",
    "\n",
    "        for f in range(nb_faces):\n",
    "            s[f] = (np.array(it) == f).sum()\n",
    "            if s.sum() == nb_faces:\n",
    "                break\n",
    "        S.append(s)\n",
    "\n",
    "    S,counts = np.unique(S, axis=0, return_counts=True)\n",
    "    return list(S), counts/counts.sum()\n",
    "\n",
    "def get_actions_from_state(my_States,nb_faces):\n",
    "    #nb_actions = np.prod(my_States+1)\n",
    "\n",
    "    nb_actions=np.prod(my_States+1)\n",
    "    #print(nb_actions)\n",
    "    Actions = np.zeros((nb_actions,nb_faces),dtype='int')\n",
    "    l = []\n",
    "    for f in range(nb_faces):\n",
    "        l.append(list(np.arange(my_States[f]+1)))\n",
    "    k = 0\n",
    "    # then generate all the possible actions\n",
    "    for i in itertools.product(*l):\n",
    "        Actions[k,:] = np.array(i)\n",
    "        k = k + 1\n",
    "    return Actions\n",
    "\n",
    "def get_states_from_action(my_actions,nb_dices):\n",
    "    r = nb_dices - my_actions.sum()\n",
    "    #print(my_actions.sum())\n",
    "    ls,lp = get_states(r,NB_FACES)\n",
    "    S = ls + my_actions\n",
    "    return S ,lp\n",
    "\n",
    "def get_state_index(my_state,my_states,nb_faces):\n",
    "    return np.argwhere((my_state == my_states).sum(axis=1) == nb_faces)[0][0]\n",
    "\n",
    "def set_last_rewards(s,nb_faces):\n",
    "    a = np.arange(1,nb_faces+1)\n",
    "    r = 0\n",
    "    if list(s).count(1) == 3:\n",
    "        num = []\n",
    "        for i in range(len(s)):\n",
    "            if s[i] == 1:\n",
    "                num.append(i)\n",
    "            if num == [0,1,2,3] or num == [1,2,3,4] or num == [2,3,4,5]:\n",
    "                r = 25\n",
    "            \n",
    "    else:\n",
    "        if list(s).count(1) == 5:\n",
    "            num = []\n",
    "            for i in range(len(s)):\n",
    "                   if s[i] == 1:\n",
    "                           num.append(i)\n",
    "            if num == [1,2,3,4,5] or num == [0,1,2,3,4]:\n",
    "                r = 40\n",
    "            \n",
    "        else:\n",
    "            for i in s: \n",
    "                if i == 3:\n",
    "                    for j in s[i:]: \n",
    "                        if j == 2: \n",
    "                            r = 25 #full\n",
    "                        else: \n",
    "                            r = np.sum(s*a) #brelan\n",
    "                if i == 4:\n",
    "                    r = np.sum(s*a) #carré\n",
    "                if i == 5: \n",
    "                    r = 50\n",
    "    if r == 0:\n",
    "        r = np.sum(a*s)\n",
    "        \n",
    "    return r\n",
    "\n",
    "def calcul_R_A(S,R0, nb_faces,nb_dices):\n",
    "    A_optimal = []\n",
    "    R = []\n",
    "    for s in S:\n",
    "        A = get_actions_from_state(s,nb_faces)\n",
    "        ra = 0 #reward moyenne de cette action\n",
    "        Ra = []\n",
    "        for a in A:\n",
    "            Sa, Pa = get_states_from_action(a,nb_dices)\n",
    "            ra = 0\n",
    "            for i,sa in enumerate(Sa):\n",
    "                ra += R0[get_state_index(sa,S,nb_faces)]*Pa[i]\n",
    "            Ra.append(ra)\n",
    "        index = Ra.index(max(Ra))\n",
    "        R.append(max(Ra))\n",
    "        A_optimal.append(np.sum(A[index]))\n",
    "    return R, A_optimal\n",
    "\n",
    "def optimal_policy1(nb_dices, nb_faces): \n",
    "    States, Probs = get_states(nb_dices,nb_faces)\n",
    "    Rewards = []\n",
    "    for state in States: \n",
    "        Rewards.append(set_last_rewards(state, nb_faces))\n",
    "\n",
    "    Value_func = np.zeros(len(States))\n",
    "    Action1_optimal = []\n",
    "    Value_func_1 = []\n",
    "    for state in States:\n",
    "        Actions = get_actions_from_state(state,nb_faces)\n",
    "        Q_avg = []\n",
    "        for action in Actions:\n",
    "            action_states, action_probs = get_states_from_action(action,nb_dices)\n",
    "            q_avg = 0\n",
    "            for i,action_state in enumerate(action_states):\n",
    "                q_avg += Rewards[get_state_index(action_state,States,nb_faces)]*action_probs[i]\n",
    "            Q_avg.append(q_avg)\n",
    "        index_max_q = Q_avg.index(max(Q_avg))\n",
    "        Action1_optimal.append(np.sum(Actions[index_max_q]))\n",
    "        Value_func_1.append(max(Q_avg))\n",
    "        \n",
    "    Value_func_2 = []\n",
    "    Action2_optimal = []\n",
    "    for state in States:\n",
    "        Actions = get_actions_from_state(state,nb_faces)\n",
    "        Q_avg = []\n",
    "        for action in Actions:\n",
    "            action_states, action_probs = get_states_from_action(action,nb_dices)\n",
    "            q_avg = 0\n",
    "            for i,action_state in enumerate(action_states):\n",
    "                q_avg += Value_func_1[get_state_index(action_state,States,nb_faces)]*action_probs[i]\n",
    "            Q_avg.append(q_avg)\n",
    "        index_max_q = Q_avg.index(max(Q_avg))\n",
    "        Value_func_2.append(max(Q_avg))\n",
    "        Action2_optimal.append(np.sum(Actions[index_max_q]))\n",
    "    Value_func_f = np.zeros((len(States), 3))\n",
    "    #Value_func_f[:,0] = States\n",
    "    Value_func_f[:,0] = Rewards\n",
    "    Value_func_f[:,1] = Value_func_1\n",
    "    Value_func_f[:,2] = Value_func_2\n",
    "    Optimal_Actions = np.zeros((len(States),2))\n",
    "    #Actions[:,1] = States\n",
    "    Optimal_Actions[:,0] = Action1_optimal\n",
    "    Optimal_Actions[:,1] = Action2_optimal\n",
    "    return Value_func_f,Optimal_Actions, States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f41a5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up environment Variables\n",
    "NB_DICES = 5\n",
    "NB_FACES = 6\n",
    "# Compute the optimal Policy\n",
    "Value_func_f, Optimal_Actions, States = optimal_policy1(NB_DICES,NB_FACES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a525a6",
   "metadata": {},
   "source": [
    "### For Each state the optimal policy is computed and the results in the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7303f9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Face1</th>\n",
       "      <th>Face2</th>\n",
       "      <th>Face3</th>\n",
       "      <th>Face4</th>\n",
       "      <th>Face5</th>\n",
       "      <th>Face6</th>\n",
       "      <th>V0</th>\n",
       "      <th>A1</th>\n",
       "      <th>V1</th>\n",
       "      <th>A2</th>\n",
       "      <th>V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.833333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.166667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.843364</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.273748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.861111</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.273748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.245242</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.273748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.245242</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.273748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Face1  Face2  Face3  Face4  Face5  Face6    V0   A1         V1   A2  \\\n",
       "0        0      0      0      0      0      5  50.0  5.0  50.000000  5.0   \n",
       "1        0      0      0      0      1      4  29.0  4.0  30.833333  4.0   \n",
       "2        0      0      0      0      2      3  28.0  5.0  28.000000  3.0   \n",
       "3        0      0      0      0      3      2  25.0  4.0  25.166667  4.0   \n",
       "4        0      0      0      0      4      1  26.0  4.0  27.666667  4.0   \n",
       "..     ...    ...    ...    ...    ...    ...   ...  ...        ...  ...   \n",
       "247      4      0      0      0      1      0   9.0  1.0  19.843364  4.0   \n",
       "248      4      0      0      1      0      0   8.0  1.0  18.861111  4.0   \n",
       "249      4      0      1      0      0      0   7.0  0.0  18.245242  4.0   \n",
       "250      4      1      0      0      0      0   6.0  0.0  18.245242  4.0   \n",
       "251      5      0      0      0      0      0  50.0  5.0  50.000000  5.0   \n",
       "\n",
       "            V2  \n",
       "0    50.000000  \n",
       "1    34.027778  \n",
       "2    28.018519  \n",
       "3    25.777778  \n",
       "4    31.388889  \n",
       "..         ...  \n",
       "247  24.273748  \n",
       "248  24.273748  \n",
       "249  24.273748  \n",
       "250  24.273748  \n",
       "251  50.000000  \n",
       "\n",
       "[252 rows x 11 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = [\"Face1\",\"Face2\",\"Face3\",\"Face4\",\"Face5\",\"Face6\"]\n",
    "df_states = pd.DataFrame(States, columns=columns)\n",
    "\n",
    "columns = [\"V0\",\"V1\",\"V2\"]\n",
    "df_value_func_f = pd.DataFrame(Value_func_f, columns=columns)\n",
    "\n",
    "columns = [\"A1\",\"A2\"]\n",
    "df_Optimal_Actions = pd.DataFrame(Optimal_Actions, columns=columns)\n",
    "df_optimal_pol = pd.concat([df_states, df_value_func_f,df_Optimal_Actions], axis=1)\n",
    "df_optimal_pol_f = df_optimal_pol.loc[:, [\"Face1\",\"Face2\",\"Face3\",\"Face4\",\"Face5\",\"Face6\", \"V0\", \"A1\", \"V1\", \"A2\",\"V2\"]]\n",
    "df_optimal_pol_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62bb7d",
   "metadata": {},
   "source": [
    "   The concept is that during each turn, a player has three chances to roll the highest possible amount on 5 6-sided dice. All dice are rolled at first <b>A0</b>, and then the player gets to choose which dice to hold and which to re-roll on subsequent rolls <b>A1</b>. The final roll is scored according to the following table <b>A2</b>\n",
    "\n",
    "The state space S is the set of distinct sorted rolls of 5 6-sided dice (5d6). There are 65=7776 possible 5d6 rolls, but resulting in only 252 distinct sorted dice patterns, so |S|=252. \n",
    "\n",
    "- V0 is the Initial Returns\n",
    "- A1 is the 2nd Action taken after:\n",
    "    - 5: keep 5 dices\n",
    "    - 4: keep 4 dices and reroll 1 dice\n",
    "    - 3: keep 3 dices and reroll 2 dices\n",
    "    - 2: keep 3 dices and reroll 2 dices\n",
    "    - 1: keep 1 dices and reroll 4 dices\n",
    "    - 0: reroll all dices\n",
    "- V1 is the rewars returnes of Action1\n",
    "- A2 is the 3rd action taken after V1\n",
    "- V2 is the final reward or gain\n",
    "\n",
    "So each row in the dataframe represents the Optimal policy taken for each state the maximizes the Rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8fd3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
